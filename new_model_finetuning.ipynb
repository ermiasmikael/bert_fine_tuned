{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ermiasmikael/bert_fine_tuned/blob/master/new_model_finetuning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install fuzzywuzzy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bk8BlnRIm-km",
        "outputId": "bf2df4be-c0c9-4f2e-e9d7-627660698a6a"
      },
      "id": "Bk8BlnRIm-km",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: fuzzywuzzy in /usr/local/lib/python3.10/dist-packages (0.18.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install python-Levenshtein"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rcIfgMq-nBbR",
        "outputId": "05b54228-6f75-4aad-bd6e-558d578975a6"
      },
      "id": "rcIfgMq-nBbR",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: python-Levenshtein in /usr/local/lib/python3.10/dist-packages (0.26.1)\n",
            "Requirement already satisfied: Levenshtein==0.26.1 in /usr/local/lib/python3.10/dist-packages (from python-Levenshtein) (0.26.1)\n",
            "Requirement already satisfied: rapidfuzz<4.0.0,>=3.9.0 in /usr/local/lib/python3.10/dist-packages (from Levenshtein==0.26.1->python-Levenshtein) (3.10.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "6a9cdf7d-20d1-4c74-b0a4-00abdec844c4",
      "metadata": {
        "id": "6a9cdf7d-20d1-4c74-b0a4-00abdec844c4"
      },
      "outputs": [],
      "source": [
        "# General imports\n",
        "import os\n",
        "import json\n",
        "import warnings\n",
        "from collections import Counter\n",
        "import random\n",
        "\n",
        "import seaborn as sns\n",
        "from wordcloud import WordCloud\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Data handling and preprocessing\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report, confusion_matrix\n",
        "\n",
        "# PyTorch and Transformers\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader, TensorDataset, random_split\n",
        "from transformers import AdamW, get_linear_schedule_with_warmup\n",
        "from torch.nn.utils import clip_grad_norm_\n",
        "from transformers import (\n",
        "    AutoTokenizer,\n",
        "    AutoModelForSequenceClassification,\n",
        "    AutoConfig,\n",
        "    AdamW,\n",
        "    get_linear_schedule_with_warmup,\n",
        "    BertTokenizer,\n",
        "    DataCollatorWithPadding\n",
        ")\n",
        "from torch.cuda.amp import GradScaler, autocast\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "# LoRA (Parameter-Efficient Fine-Tuning)\n",
        "from peft import LoraConfig, get_peft_model, PeftModel, PeftType, TaskType\n",
        "\n",
        "# Logging and Debugging\n",
        "import logging\n",
        "\n",
        "# Suppress warnings and logging messages\n",
        "warnings.filterwarnings('ignore')\n",
        "logging.getLogger(\"transformers.modeling_utils\").setLevel(logging.ERROR)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load, split in chunks, tensorize, train/test split\n",
        "data = pd.read_csv(\"dsm5_disorders.csv\")\n",
        "\n",
        "# Step 1: Create label mapping for broad_category\n",
        "label_mapping = {category: idx for idx, category in enumerate(data['broad_category'].unique())}\n",
        "data['label_encoded'] = data['broad_category'].map(label_mapping)\n",
        "\n",
        "# Save the label mapping\n",
        "with open(\"label_mapping.json\", \"w\") as f:\n",
        "    json.dump(label_mapping, f)\n",
        "print(\"Label mapping saved:\", label_mapping)\n",
        "\n",
        "# Verify encoded labels\n",
        "print(\"Sample Data with Encoded Labels:\")\n",
        "print(data[['broad_category', 'label_encoded']].head())\n",
        "\n",
        "# Step 2: Train/Test/Val Split (retain all columns)\n",
        "train_data, temp_data = train_test_split(\n",
        "    data,\n",
        "    test_size=0.3,\n",
        "    random_state=42,\n",
        "    stratify=data['label_encoded']\n",
        ")\n",
        "\n",
        "test_data, val_data = train_test_split(\n",
        "    temp_data,\n",
        "    test_size=0.5,\n",
        "    random_state=42,\n",
        "    stratify=temp_data['label_encoded']\n",
        ")\n",
        "\n",
        "\n",
        "# Step 3: Tokenizer\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"emilyalsentzer/Bio_ClinicalBERT\")\n",
        "\n",
        "# Function: Split long text into chunks\n",
        "def split_text_into_chunks(text, max_length, tokenizer):\n",
        "    tokens = tokenizer.tokenize(text)\n",
        "    chunks = []\n",
        "    for i in range(0, len(tokens), max_length):\n",
        "        chunk = tokens[i:i + max_length]\n",
        "        chunks.append(tokenizer.convert_tokens_to_string(chunk))\n",
        "    return chunks\n",
        "\n",
        "# Preprocess data (splitting long texts into chunks while retaining all columns)\n",
        "def preprocess_data(data, tokenizer, max_length=512):\n",
        "    new_records = []\n",
        "    for _, row in data.iterrows():\n",
        "        combined_text = f\"{row['text']} {row['back_translated_text']}\"\n",
        "        text_chunks = split_text_into_chunks(combined_text, max_length - 2, tokenizer)  # Reserve space for special tokens\n",
        "        for chunk in text_chunks:\n",
        "            new_records.append({\n",
        "                'text': chunk,\n",
        "                'broad_category': row['broad_category'],\n",
        "                'category': row['category'],\n",
        "                'label_encoded': row['label_encoded']\n",
        "            })\n",
        "    return pd.DataFrame(new_records)\n",
        "\n",
        "# Preprocess train and test data\n",
        "train_data = preprocess_data(train_data, tokenizer)\n",
        "val_data = preprocess_data(val_data, tokenizer)\n",
        "test_data = preprocess_data(test_data, tokenizer)\n",
        "\n",
        "# Step 4: Tokenize data\n",
        "def tokenize_data(data, tokenizer):\n",
        "    texts = data['text'].tolist()\n",
        "    labels = data['label_encoded'].tolist()\n",
        "\n",
        "    tokenized = tokenizer(\n",
        "        texts,\n",
        "        padding=True,\n",
        "        truncation=True,\n",
        "        max_length=512,\n",
        "        return_tensors=\"pt\"\n",
        "    )\n",
        "    features = []\n",
        "    for i in range(len(labels)):\n",
        "        features.append({\n",
        "            \"input_ids\": tokenized[\"input_ids\"][i],\n",
        "            \"attention_mask\": tokenized[\"attention_mask\"][i],\n",
        "            \"labels\": torch.tensor(labels[i], dtype=torch.long)\n",
        "        })\n",
        "    return features\n",
        "\n",
        "# Tokenize train, validation, and test data\n",
        "train_features = tokenize_data(train_data, tokenizer)\n",
        "val_features = tokenize_data(val_data, tokenizer)\n",
        "test_features = tokenize_data(test_data, tokenizer)\n",
        "\n",
        "# Step 5: DataLoader\n",
        "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
        "\n",
        "train_loader = DataLoader(train_features, batch_size=2, shuffle=True, collate_fn=data_collator)\n",
        "val_loader = DataLoader(val_features, batch_size=2, shuffle=False, collate_fn=data_collator)\n",
        "test_loader = DataLoader(test_features, batch_size=2, shuffle=False, collate_fn=data_collator)\n",
        "\n",
        "# Step 6: Verify Tokenization\n",
        "for batch in train_loader:\n",
        "    print(\"Input IDs:\", batch[\"input_ids\"].shape)\n",
        "    print(\"Attention Mask:\", batch[\"attention_mask\"].shape)\n",
        "    print(\"Labels:\", batch[\"labels\"].shape)\n",
        "    break\n",
        "\n",
        "# Step 7: Check for label mismatches\n",
        "mismatched_labels = []\n",
        "for label in train_data['broad_category']:\n",
        "    if label not in label_mapping:\n",
        "        mismatched_labels.append(label)\n",
        "\n",
        "if mismatched_labels:\n",
        "    print(\"Mismatched Labels Found:\", mismatched_labels)\n",
        "else:\n",
        "    print(\"All tokenized labels match the label_mapping keys!\")\n",
        "\n",
        "# Check unique labels in the dataset against label_mapping\n",
        "unique_labels = train_data['broad_category'].unique()\n",
        "missing_keys = [label for label in unique_labels if label not in label_mapping]\n",
        "if missing_keys:\n",
        "    print(\"Missing Keys in label_mapping:\", missing_keys)\n",
        "else:\n",
        "    print(\"All dataset labels are covered by label_mapping!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c1wews3eRzjD",
        "outputId": "37716e59-a185-4186-873f-159ac0d91902"
      },
      "id": "c1wews3eRzjD",
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Label mapping saved: {'somatic symptom and related disorders': 0, 'motor disorders': 1, 'gender dysphoria': 2, 'medication-induced movement disorders and other adverse effects of medication': 3, 'dissociative disorders': 4, 'opioid-related disorders': 5, 'other conditions that may be a focus of clinical attention': 6, 'alcohol-induced mental disorders': 7, 'obsessive-compulsive and related disorders': 8, 'sexual dysfunctions': 9, 'neurodevelopmental disorders': 10, 'anxiety disorders': 11, 'trauma- and stressor-related disorders': 12, 'inhalant-related disorders': 13, 'neurocognitive disorders': 14, 'other mental disorders and additional codes': 15, 'personality disorders': 16, 'elimination disorders': 17, 'tobacco-related disorders': 18, 'paraphilic disorders': 19, 'bipolar and related disorders': 20, 'schizophrenia spectrum and other psychotic disorders': 21, 'sleep-wake disorders': 22, 'feeding and eating disorders': 23, 'depressive disorders': 24, 'disruptive, impulse-control, and conduct disorders': 25}\n",
            "Sample Data with Encoded Labels:\n",
            "                          broad_category  label_encoded\n",
            "0  somatic symptom and related disorders              0\n",
            "1  somatic symptom and related disorders              0\n",
            "2  somatic symptom and related disorders              0\n",
            "3  somatic symptom and related disorders              0\n",
            "4  somatic symptom and related disorders              0\n",
            "Input IDs: torch.Size([2, 512])\n",
            "Attention Mask: torch.Size([2, 512])\n",
            "Labels: torch.Size([2])\n",
            "All tokenized labels match the label_mapping keys!\n",
            "All dataset labels are covered by label_mapping!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load, split in chunks, tensorize, train/test split\n",
        "data = pd.read_csv(\"dsm5_disorders.csv\")\n",
        "\n",
        "# Step 1: Create label mapping for broad_category\n",
        "label_mapping = {category: idx for idx, category in enumerate(data['broad_category'].unique())}\n",
        "data['label_encoded'] = data['broad_category'].map(label_mapping)\n",
        "\n",
        "# Save the label mapping\n",
        "with open(\"label_mapping.json\", \"w\") as f:\n",
        "    json.dump(label_mapping, f)\n",
        "print(\"Label mapping saved:\", label_mapping)\n",
        "\n",
        "# Verify encoded labels\n",
        "print(\"Sample Data with Encoded Labels:\")\n",
        "print(data[['broad_category', 'label_encoded']].head())\n",
        "\n",
        "# Step 2: Train/Test/Val Split (retain all columns)\n",
        "train_data, temp_data = train_test_split(\n",
        "    data,\n",
        "    test_size=0.3,\n",
        "    random_state=42,\n",
        "    stratify=data['label_encoded']\n",
        ")\n",
        "\n",
        "test_data, val_data = train_test_split(\n",
        "    temp_data,\n",
        "    test_size=0.5,\n",
        "    random_state=42,\n",
        "    stratify=temp_data['label_encoded']\n",
        ")\n",
        "\n",
        "\n",
        "# Step 3: Tokenizer\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"emilyalsentzer/Bio_ClinicalBERT\")\n",
        "\n",
        "# Function: Split long text into chunks\n",
        "def split_text_into_chunks(text, max_length, tokenizer, overlap=0):\n",
        "    tokens = tokenizer.tokenize(text)\n",
        "    chunks = []\n",
        "    stride = max_length - overlap\n",
        "    for i in range(0, len(tokens), stride):\n",
        "        chunk = tokens[i:i + max_length]\n",
        "        chunk_text = tokenizer.convert_tokens_to_string(chunk)\n",
        "        chunks.append(chunk_text)\n",
        "    return chunks\n",
        "\n",
        "# Preprocess data (splitting long texts into chunks while retaining all columns)\n",
        "def preprocess_data(data, tokenizer, max_length=512):\n",
        "    new_records = []\n",
        "    for _, row in data.iterrows():\n",
        "        combined_text = f\"{row['text']} {row['back_translated_text']}\"\n",
        "        text_chunks = split_text_into_chunks(combined_text, max_length - 2, tokenizer)  # Reserve space for special tokens\n",
        "        for chunk in text_chunks:\n",
        "            new_records.append({\n",
        "                'text': chunk,\n",
        "                'broad_category': row['broad_category'],\n",
        "                'category': row['category'],\n",
        "                'label_encoded': row['label_encoded']\n",
        "            })\n",
        "    return pd.DataFrame(new_records)\n",
        "\n",
        "# Preprocess train and test data\n",
        "train_data = preprocess_data(train_data, tokenizer)\n",
        "val_data = preprocess_data(val_data, tokenizer)\n",
        "test_data = preprocess_data(test_data, tokenizer)\n",
        "\n",
        "def tokenize_data(data, tokenizer):\n",
        "    texts = data['text'].tolist()  # This 'text' already contains back_translated_text\n",
        "    labels = data['label_encoded'].tolist()\n",
        "    broad_categories = data['broad_category'].tolist()\n",
        "    categories = data['category'].tolist()\n",
        "\n",
        "    # Tokenize 'text' (which already includes back_translated_text)\n",
        "    tokenized_text = tokenizer(\n",
        "        texts,\n",
        "        padding=True,\n",
        "        truncation=True,\n",
        "        max_length=512,  # Adjust as needed\n",
        "        return_tensors=\"pt\"\n",
        "    )\n",
        "\n",
        "    # Tokenize 'broad_category'\n",
        "    tokenized_broad_cat = tokenizer(\n",
        "        broad_categories,\n",
        "        padding=True,\n",
        "        truncation=True,\n",
        "        max_length=64,  # Adjust as needed\n",
        "        return_tensors=\"pt\"\n",
        "    )\n",
        "\n",
        "    # Tokenize 'category'\n",
        "    tokenized_cat = tokenizer(\n",
        "        categories,\n",
        "        padding=True,\n",
        "        truncation=True,\n",
        "        max_length=64,  # Adjust as needed\n",
        "        return_tensors=\"pt\"\n",
        "    )\n",
        "\n",
        "    features = []\n",
        "    for i in range(len(texts)):\n",
        "        features.append({\n",
        "            \"input_ids\": tokenized_text[\"input_ids\"][i],\n",
        "            \"attention_mask\": tokenized_text[\"attention_mask\"][i],\n",
        "            \"broad_category_input_ids\": tokenized_broad_cat[\"input_ids\"][i],\n",
        "            \"broad_category_attention_mask\": tokenized_broad_cat[\"attention_mask\"][i],\n",
        "            \"category_input_ids\": tokenized_cat[\"input_ids\"][i],\n",
        "            \"category_attention_mask\": tokenized_cat[\"attention_mask\"][i],\n",
        "            \"labels\": torch.tensor(labels[i], dtype=torch.long)\n",
        "        })\n",
        "    return features\n",
        "\n",
        "# Tokenize train, validation, and test data\n",
        "train_features = tokenize_data(train_data, tokenizer)\n",
        "val_features = tokenize_data(val_data, tokenizer)\n",
        "test_features = tokenize_data(test_data, tokenizer)\n",
        "\n",
        "# Step 5: DataLoader\n",
        "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
        "\n",
        "train_loader = DataLoader(train_features, batch_size=2, shuffle=True, collate_fn=data_collator)\n",
        "val_loader = DataLoader(val_features, batch_size=2, shuffle=False, collate_fn=data_collator)\n",
        "test_loader = DataLoader(test_features, batch_size=2, shuffle=False, collate_fn=data_collator)\n",
        "\n",
        "# Step 6: Verify Tokenization\n",
        "for batch in train_loader:\n",
        "    print(\"Input IDs:\", batch[\"input_ids\"].shape)\n",
        "    print(\"Attention Mask:\", batch[\"attention_mask\"].shape)\n",
        "    print(\"Labels:\", batch[\"labels\"].shape)\n",
        "    break\n",
        "\n",
        "# Step 7: Check for label mismatches\n",
        "mismatched_labels = []\n",
        "for label in train_data['broad_category']:\n",
        "    if label not in label_mapping:\n",
        "        mismatched_labels.append(label)\n",
        "\n",
        "if mismatched_labels:\n",
        "    print(\"Mismatched Labels Found:\", mismatched_labels)\n",
        "else:\n",
        "    print(\"All tokenized labels match the label_mapping keys!\")\n",
        "\n",
        "# Check unique labels in the dataset against label_mapping\n",
        "unique_labels = train_data['broad_category'].unique()\n",
        "missing_keys = [label for label in unique_labels if label not in label_mapping]\n",
        "if missing_keys:\n",
        "    print(\"Missing Keys in label_mapping:\", missing_keys)\n",
        "else:\n",
        "    print(\"All dataset labels are covered by label_mapping!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aW2kzwC6vZMa",
        "outputId": "ad305141-1568-495b-d41c-9624a57ac072"
      },
      "id": "aW2kzwC6vZMa",
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Label mapping saved: {'somatic symptom and related disorders': 0, 'motor disorders': 1, 'gender dysphoria': 2, 'medication-induced movement disorders and other adverse effects of medication': 3, 'dissociative disorders': 4, 'opioid-related disorders': 5, 'other conditions that may be a focus of clinical attention': 6, 'alcohol-induced mental disorders': 7, 'obsessive-compulsive and related disorders': 8, 'sexual dysfunctions': 9, 'neurodevelopmental disorders': 10, 'anxiety disorders': 11, 'trauma- and stressor-related disorders': 12, 'inhalant-related disorders': 13, 'neurocognitive disorders': 14, 'other mental disorders and additional codes': 15, 'personality disorders': 16, 'elimination disorders': 17, 'tobacco-related disorders': 18, 'paraphilic disorders': 19, 'bipolar and related disorders': 20, 'schizophrenia spectrum and other psychotic disorders': 21, 'sleep-wake disorders': 22, 'feeding and eating disorders': 23, 'depressive disorders': 24, 'disruptive, impulse-control, and conduct disorders': 25}\n",
            "Sample Data with Encoded Labels:\n",
            "                          broad_category  label_encoded\n",
            "0  somatic symptom and related disorders              0\n",
            "1  somatic symptom and related disorders              0\n",
            "2  somatic symptom and related disorders              0\n",
            "3  somatic symptom and related disorders              0\n",
            "4  somatic symptom and related disorders              0\n",
            "Input IDs: torch.Size([2, 512])\n",
            "Attention Mask: torch.Size([2, 512])\n",
            "Labels: torch.Size([2])\n",
            "All tokenized labels match the label_mapping keys!\n",
            "All dataset labels are covered by label_mapping!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "666e1aa9-c495-49c3-b0d9-6699275dbdcd",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "666e1aa9-c495-49c3-b0d9-6699275dbdcd",
        "outputId": "a90e37dd-fea8-4cf5-e8a0-e6f9420b5c2e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Small sample dataset created with 300 examples for pre-tuning evaluation.\n",
            "Input IDs Shape: torch.Size([16, 512])\n",
            "Attention Masks Shape: torch.Size([16, 512])\n",
            "Labels Shape: torch.Size([16])\n"
          ]
        }
      ],
      "source": [
        "sample_size = 300\n",
        "batch_size = 16\n",
        "\n",
        "sample_indices = random.sample(range(len(train_features)), min(sample_size, len(train_features)))\n",
        "\n",
        "sample_input_ids = [train_features[i][\"input_ids\"] for i in sample_indices]\n",
        "sample_attention_masks = [train_features[i][\"attention_mask\"] for i in sample_indices]\n",
        "sample_labels = [train_features[i][\"labels\"] for i in sample_indices]\n",
        "\n",
        "sample_input_ids = torch.stack(sample_input_ids)\n",
        "sample_attention_masks = torch.stack(sample_attention_masks)\n",
        "sample_labels = torch.stack(sample_labels)\n",
        "\n",
        "sample_dataloader = DataLoader(\n",
        "    TensorDataset(sample_input_ids, sample_attention_masks, sample_labels),\n",
        "    batch_size=batch_size,\n",
        "    shuffle=False\n",
        ")\n",
        "\n",
        "print(f\"Small sample dataset created with {len(sample_indices)} examples for pre-tuning evaluation.\")\n",
        "\n",
        "# Inspect the sample\n",
        "for batch in sample_dataloader:\n",
        "    print(\"Input IDs Shape:\", batch[0].shape)\n",
        "    print(\"Attention Masks Shape:\", batch[1].shape)\n",
        "    print(\"Labels Shape:\", batch[2].shape)\n",
        "    max_length = batch[0].shape[1]\n",
        "    assert max_length <= 512, f\"Error: Batch contains sequence of length {max_length}!\"\n",
        "    break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "07c59beb-6ab8-436f-9a51-5406a62d5da8",
      "metadata": {
        "id": "07c59beb-6ab8-436f-9a51-5406a62d5da8"
      },
      "outputs": [],
      "source": [
        "# Defining model evaluation function\n",
        "def evaluate_model(model, dataloader):\n",
        "\n",
        "    model.eval()\n",
        "    total_loss = 0\n",
        "    all_preds = []\n",
        "    all_labels = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for i, batch in enumerate(dataloader):\n",
        "            input_ids = batch[0].to(device)\n",
        "            attention_masks = batch[1].to(device)\n",
        "            labels = batch[2].to(device)\n",
        "\n",
        "            outputs = model(input_ids, attention_mask=attention_masks, labels=labels)\n",
        "            loss, logits = outputs.loss, outputs.logits\n",
        "\n",
        "            total_loss += loss.item()\n",
        "            preds = torch.argmax(logits, dim=1)\n",
        "\n",
        "            all_preds.extend(preds.cpu().numpy())\n",
        "            all_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "    # Normalize loss\n",
        "    avg_loss = total_loss / len(dataloader)\n",
        "\n",
        "    # Compute overall metrics\n",
        "    accuracy = accuracy_score(all_labels, all_preds)\n",
        "    precision = precision_score(all_labels, all_preds, average='weighted', zero_division=0)\n",
        "    recall = recall_score(all_labels, all_preds, average='weighted', zero_division=0)\n",
        "    f1 = f1_score(all_labels, all_preds, average='weighted', zero_division=0)\n",
        "\n",
        "    return avg_loss, accuracy, precision, recall, f1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "26b5726c-ae0b-493d-950b-b6b9853e15f8",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "26b5726c-ae0b-493d-950b-b6b9853e15f8",
        "outputId": "8b4c6cde-1a66-41a4-d99b-75382dc9c028"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting pre-fine-tuning evaluation...\n",
            "\n",
            "Evaluation Results:\n",
            "Loss: 3.3112\n",
            "Accuracy: 4.00%\n",
            "Precision: 0.18%\n",
            "Recall: 4.00%\n",
            "F1: 0.34%\n"
          ]
        }
      ],
      "source": [
        "# Pre-tuning model evaluation against the sample data:\n",
        "num_labels = len(label_mapping)\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = AutoModelForSequenceClassification.from_pretrained(\n",
        "    \"emilyalsentzer/Bio_ClinicalBERT\", num_labels=num_labels\n",
        ").to(device)\n",
        "\n",
        "\n",
        "print(\"Starting pre-fine-tuning evaluation...\\n\")\n",
        "avg_loss, accuracy, precision, recall, f1 = evaluate_model(model, sample_dataloader)\n",
        "print('Evaluation Results:')\n",
        "print(f'Loss: {avg_loss:.4f}')\n",
        "print(f'Accuracy: {accuracy * 100:.2f}%')\n",
        "print(f'Precision: {precision * 100:.2f}%')\n",
        "print(f'Recall: {recall * 100:.2f}%')\n",
        "print(f'F1: {f1 * 100:.2f}%')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "07be4c75-d51c-4967-bbe5-f4f7393eb930",
      "metadata": {
        "id": "07be4c75-d51c-4967-bbe5-f4f7393eb930",
        "outputId": "932f9396-5b36-4606-bd44-084600fe1fc4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "trainable params: 2,379,290 || all params: 110,709,556 || trainable%: 2.1491\n"
          ]
        }
      ],
      "source": [
        "# Model initialization with PEFT\n",
        "\n",
        "model_name = \"emilyalsentzer/Bio_ClinicalBERT\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "\n",
        "num_labels = len(label_mapping)\n",
        "\n",
        "base_model = AutoModelForSequenceClassification.from_pretrained(\n",
        "    model_name,\n",
        "    num_labels=num_labels\n",
        ")\n",
        "\n",
        "# Define LoRA configuration\n",
        "lora_config = LoraConfig(\n",
        "    task_type=TaskType.SEQ_CLS,\n",
        "    inference_mode=False,\n",
        "    r=64,\n",
        "    lora_alpha=128,\n",
        "    lora_dropout=0.1\n",
        ")\n",
        "\n",
        "model = get_peft_model(base_model, lora_config).to(device)\n",
        "#print(model)\n",
        "model.print_trainable_parameters()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Defining model evaluation function\n",
        "def evaluate_fine_tuning(model, dataloader):\n",
        "    model.eval()\n",
        "    total_loss = 0\n",
        "    all_preds = []\n",
        "    all_labels = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for i, batch in enumerate(dataloader):\n",
        "            # Access tensors using keys instead of numerical indices\n",
        "            input_ids = batch[\"input_ids\"].to(device)\n",
        "            attention_masks = batch[\"attention_mask\"].to(device)\n",
        "            labels = batch[\"labels\"].to(device)\n",
        "\n",
        "            outputs = model(input_ids, attention_mask=attention_masks, labels=labels)\n",
        "            loss, logits = outputs.loss, outputs.logits\n",
        "\n",
        "            total_loss += loss.item()\n",
        "            preds = torch.argmax(logits, dim=1)\n",
        "\n",
        "            all_preds.extend(preds.cpu().numpy())\n",
        "            all_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "    # Normalize loss\n",
        "    avg_loss = total_loss / len(dataloader)\n",
        "\n",
        "    # Compute overall metrics\n",
        "    accuracy = accuracy_score(all_labels, all_preds)\n",
        "    precision = precision_score(all_labels, all_preds, average='weighted', zero_division=0)\n",
        "    recall = recall_score(all_labels, all_preds, average='weighted', zero_division=0)\n",
        "    f1 = f1_score(all_labels, all_preds, average='weighted', zero_division=0)\n",
        "\n",
        "    return avg_loss, accuracy, precision, recall, f1"
      ],
      "metadata": {
        "id": "CyWUkFwqyooo"
      },
      "id": "CyWUkFwqyooo",
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "ea4c1f49-09e5-4fcc-80e4-39ddd5dfd9ef",
      "metadata": {
        "id": "ea4c1f49-09e5-4fcc-80e4-39ddd5dfd9ef",
        "outputId": "e66b29c2-15e0-4b20-a531-830f665d66c8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting training...\n",
            "\n",
            "Epoch 1 results:\n",
            "Loss:0.9271 Accuracy:77.11% Precision:78.94% Recall:77.11% F1:76.60%\n",
            "\n",
            "Epoch 2 results:\n",
            "Loss:0.9153 Accuracy:76.37% Precision:77.89% Recall:76.37% F1:75.80%\n",
            "\n",
            "Epoch 3 results:\n",
            "Loss:0.9034 Accuracy:76.87% Precision:78.63% Recall:76.87% F1:76.30%\n",
            "Early stopping triggered.\n",
            "Training completed. Best model saved.\n"
          ]
        }
      ],
      "source": [
        "# Fine-tuning the model\n",
        "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
        "import torch.nn as nn\n",
        "\n",
        "save_directory = './dsm_finetune'\n",
        "os.makedirs(save_directory, exist_ok=True)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "optimizer = AdamW(model.parameters(), lr=1e-5, weight_decay = 0.01)\n",
        "\n",
        "total_steps = len(train_loader) * 10\n",
        "scheduler = ReduceLROnPlateau(optimizer, 'min', patience=2, factor=0.9)\n",
        "\n",
        "scaler = GradScaler()\n",
        "\n",
        "epochs = 10\n",
        "patience = 2\n",
        "no_improvement = 0\n",
        "best_f1 = 0\n",
        "\n",
        "print(\"Starting training...\")\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    if no_improvement >= patience:\n",
        "        print(\"Early stopping triggered.\")\n",
        "        break\n",
        "\n",
        "    total_train_loss = 0\n",
        "    model.train()\n",
        "\n",
        "    for step, batch in enumerate(train_loader):\n",
        "        # Access tensors from the batch dictionary\n",
        "        input_ids = batch[\"input_ids\"].to(device)\n",
        "        attention_masks = batch[\"attention_mask\"].to(device)\n",
        "        labels = batch[\"labels\"].to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Mixed precision forward pass\n",
        "        with autocast():\n",
        "            outputs = model(input_ids, attention_mask=attention_masks)\n",
        "            loss = criterion(outputs.logits, labels)\n",
        "\n",
        "        total_train_loss += loss.item()\n",
        "\n",
        "        # Mixed precision backward pass\n",
        "        scaler.scale(loss).backward()\n",
        "\n",
        "        clip_grad_norm_(model.parameters(), max_norm=1.0)  # Gradient clipping\n",
        "        scaler.step(optimizer)\n",
        "        scaler.update()\n",
        "\n",
        "    # Evaluate the model progress\n",
        "    avg_train_loss = total_train_loss / len(train_loader)\n",
        "    avg_loss, accuracy, precision, recall, f1 = evaluate_fine_tuning(model, val_loader)\n",
        "    scheduler.step(avg_loss)\n",
        "\n",
        "    # Print evaluation results for test sets\n",
        "    print(f'\\nEpoch {epoch + 1} results:')\n",
        "    print(f'Loss:{avg_loss:.4f} Accuracy:{accuracy * 100:.2f}% Precision:{precision * 100:.2f}% Recall:{recall * 100:.2f}% F1:{f1 * 100:.2f}%')\n",
        "\n",
        "    # Check for best F1 and save the best model\n",
        "    if f1 > best_f1:\n",
        "        best_f1 = f1\n",
        "        no_improvement = 0\n",
        "\n",
        "        # Save model weights\n",
        "        model_save_path = os.path.join(save_directory, 'psyai.pt')\n",
        "        torch.save(model.state_dict(), model_save_path)\n",
        "\n",
        "        # Save tokenizer and config\n",
        "        tokenizer.save_pretrained(save_directory)\n",
        "        config = AutoConfig.from_pretrained(model_name)\n",
        "        config.save_pretrained(save_directory)\n",
        "\n",
        "        with open(os.path.join(save_directory, 'int_to_label.json'), 'w') as f:\n",
        "            json.dump(label_mapping, f)\n",
        "\n",
        "        # Save training metadata\n",
        "        training_metadata = {\n",
        "            \"learning_rate\": optimizer.param_groups[0]['lr'],\n",
        "            \"epochs\": epochs,\n",
        "            \"batch_size\": train_loader.batch_size,\n",
        "            \"total_steps\": total_steps,\n",
        "            \"best_f1\": best_f1,\n",
        "            \"gradient_clipping\": 1.0,\n",
        "            \"weight_decay\": optimizer.param_groups[0].get('weight_decay', 0),\n",
        "            \"scheduler\": str(scheduler.__class__.__name__)\n",
        "        }\n",
        "        with open(os.path.join(save_directory, 'training_metadata.json'), 'w') as f:\n",
        "            json.dump(training_metadata, f)\n",
        "\n",
        "        # Save evaluation metrics\n",
        "        best_metrics = {\n",
        "            \"f1_score\": best_f1,\n",
        "            \"precision\": precision,\n",
        "            \"recall\": recall,\n",
        "            \"accuracy\": accuracy,\n",
        "        }\n",
        "        with open(os.path.join(save_directory, 'evaluation_metrics.json'), 'w') as f:\n",
        "            json.dump(best_metrics, f)\n",
        "\n",
        "    else:\n",
        "        no_improvement += 1\n",
        "\n",
        "print(\"Training completed. Best model saved.\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluating model on the test set:\n",
        "best_model_path = \"dsm_finetune/psyai.pt\"\n",
        "model = AutoModelForSequenceClassification.from_pretrained(\n",
        "    \"emilyalsentzer/Bio_ClinicalBERT\", num_labels=num_labels\n",
        ")\n",
        "model.load_state_dict(torch.load(best_model_path))\n",
        "model.to(device)\n",
        "\n",
        "print(\"Starting pre-fine-tuning evaluation...\\n\")\n",
        "avg_loss, accuracy, precision, recall, f1 = evaluate_fine_tuning(model, test_loader)\n",
        "print('Evaluation Results:')\n",
        "print(f'Loss: {avg_loss:.4f}')\n",
        "print(f'Accuracy: {accuracy * 100:.2f}%')\n",
        "print(f'Precision: {precision * 100:.2f}%')\n",
        "print(f'Recall: {recall * 100:.2f}%')\n",
        "print(f'F1: {f1 * 100:.2f}%')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iiBjnFrRc5YB",
        "outputId": "d9b3b7d7-52bd-4523-f9f6-257836c36cdf"
      },
      "id": "iiBjnFrRc5YB",
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting pre-fine-tuning evaluation...\n",
            "\n",
            "Evaluation Results:\n",
            "Loss: 0.8915\n",
            "Accuracy: 92.38%\n",
            "Precision: 92.74%\n",
            "Recall: 92.38%\n",
            "F1: 92.36%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_diagnosis(text, diagnosis_labels):\n",
        "    \"\"\"Predicts the mental health diagnosis based on the given text.\"\"\"\n",
        "    inputs = tokenizer(text, return_tensors=\"pt\", padding=True, truncation=True).to(device)\n",
        "    outputs = model(**inputs)\n",
        "    predicted_class_id = outputs.logits.argmax().item()\n",
        "    predicted_diagnosis = diagnosis_labels[predicted_class_id]\n",
        "    return predicted_diagnosis\n",
        "\n",
        "diagnosis_labels = list(label_mapping.keys())\n",
        "\n",
        "# Example usage\n",
        "text = \"I've been feeling down and hopeless for the past few weeks.\"\n",
        "predicted_diagnosis = predict_diagnosis(text, diagnosis_labels)\n",
        "print(f\"Predicted Diagnosis: {predicted_diagnosis}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kYA9pr-Wc5Wa",
        "outputId": "935ef971-9403-4227-82a1-0a25e17b85d4"
      },
      "id": "kYA9pr-Wc5Wa",
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted Diagnosis: depressive disorders\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "id": "1389dcfe-f8fe-469d-b4f7-08e1db2eabf9",
      "metadata": {
        "id": "1389dcfe-f8fe-469d-b4f7-08e1db2eabf9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c8a23826-b8fd-4287-f932-d62f1061424c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted Diagnosis: paraphilic disorders\n"
          ]
        }
      ],
      "source": [
        "text = \"I've been feeling mind-body dualism for the past few weeks.\"\n",
        "predicted_diagnosis = predict_diagnosis(text, diagnosis_labels)\n",
        "print(f\"Predicted Diagnosis: {predicted_diagnosis}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from fuzzywuzzy import fuzz, process\n",
        "\n",
        "def predict_diagnosis(text, diagnosis_labels, df, max_length=512):\n",
        "    \"\"\"Predicts the mental health diagnosis and extracts relevant information using fuzzy matching.\"\"\"\n",
        "    inputs = tokenizer(text, return_tensors=\"pt\", padding=True, truncation=True).to(device)\n",
        "    outputs = model(**inputs)\n",
        "    predicted_class_id = outputs.logits.argmax().item()\n",
        "    predicted_diagnosis = diagnosis_labels[predicted_class_id]\n",
        "\n",
        "    # Fuzzy matching to find the closest text in the DataFrame\n",
        "    best_match = process.extractOne(text, df['text'], scorer=fuzz.token_sort_ratio)\n",
        "\n",
        "    if best_match and best_match[1] > 80:  # Set a similarity threshold (e.g., 80)\n",
        "        matching_row_index = df[df['text'] == best_match[0]].index[0]\n",
        "        category = df.loc[matching_row_index, 'category']\n",
        "        summary = df.loc[matching_row_index, 'text'][:100] + \"...\"\n",
        "    else:\n",
        "        category = \"Unknown\"\n",
        "        summary = \"Not found\"\n",
        "\n",
        "    return predicted_diagnosis, category, summary\n",
        "\n",
        "# Create diagnosis_labels from label_mapping\n",
        "diagnosis_labels = list(label_mapping.keys())\n",
        "\n",
        "# Example usage (assuming 'df' is your DataFrame)\n",
        "text = \"more recent population-based studies with a questionnaire-based strategy using dsm-5 diagnostic criteria\"\n",
        "predicted_diagnosis, category, summary = predict_diagnosis(text, diagnosis_labels, data)\n",
        "print(f\"Predicted Diagnosis: {predicted_diagnosis}\")\n",
        "print(f\"Category: {category}\")\n",
        "print(f\"Summary: {summary}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ws--GRaik5nj",
        "outputId": "9668a74b-d8ac-4155-cdfd-e23fcca03608"
      },
      "id": "ws--GRaik5nj",
      "execution_count": 105,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted Diagnosis: depressive disorders\n",
            "Category: Unknown\n",
            "Summary: Not found\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.7"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}